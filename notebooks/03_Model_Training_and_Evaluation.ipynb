{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Svmxl0cNbEd"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_processed, y_train)\n",
        "rf_preds = rf_model.predict(X_test_processed)\n",
        "\n",
        "print(\"Random Forest Performance:\")\n",
        "print(classification_report(y_test, rf_preds))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, rf_preds))\n",
        "\n",
        "# Confusion matrix for Random Forest\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(confusion_matrix(y_test, rf_preds), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# XGBoost Model\n",
        "xgb_model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_model.fit(X_train_processed, y_train)\n",
        "xgb_preds = xgb_model.predict(X_test_processed)\n",
        "\n",
        "print(\"\\nXGBoost Performance:\")\n",
        "print(classification_report(y_test, xgb_preds))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, xgb_preds))\n",
        "\n",
        "# Confusion matrix for XGBoost\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(confusion_matrix(y_test, xgb_preds), annot=True, fmt='d', cmap='Greens')\n",
        "plt.title('XGBoost Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Evaluate Random Forest\n",
        "rf_precision, rf_recall, rf_f1, _ = precision_recall_fscore_support(y_test, rf_preds, average='weighted')\n",
        "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
        "\n",
        "# Evaluate XGBoost\n",
        "xgb_precision, xgb_recall, xgb_f1, _ = precision_recall_fscore_support(y_test, xgb_preds, average='weighted')\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_preds)\n",
        "\n",
        "# Organize metrics into a DataFrame\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score'],\n",
        "    'Random Forest': [rf_accuracy, rf_precision, rf_recall, rf_f1],\n",
        "    'XGBoost': [xgb_accuracy, xgb_precision, xgb_recall, xgb_f1]\n",
        "})\n",
        "\n",
        "# Format metrics as percentages\n",
        "metrics_df[['Random Forest', 'XGBoost']] = metrics_df[['Random Forest', 'XGBoost']].applymap(lambda x: f\"{x:.2%}\")\n",
        "\n",
        "# Display the DataFrame as a table\n",
        "print(metrics_df.to_string(index=False))"
      ]
    }
  ]
}